Requirements for General Intelligence: A Case Study in Trustworthy Cumulative Learning for Air Traffic Control
Jordi Bieger and Kristinn R. Thórisson

While many evaluation procedures have been proposed in past research for artificial general intelligence (AGI), few take the time to carefully list the (minimum, general) requirements that an AGI-aspiring (cognitive) control architecture is intended to eventually meet. Such requirements could guide the design process and help evaluate the potential of an architecture to become generally intelligent—not through measuring the performance of a runningAI  system, but through a white-box, offline evaluation of what requirements have been met to what degree. Rather than providing our estimate of what features are necessary to achieve AGI, we analyze a concrete task from the air traffic control (ATC) domain to come up with a crisp set of requirements that AGI would need to meet as well. To avoid major disruptions to proven workflows in safety-critical domains, a trustworthy, robust and adaptable AI system must work side-by-side with a human operator and cumulatively learn new tasks that can gradually be introduced into the operator’s complex workflow. Our analysis results in a set of minimal/necessary requirements that can guide the development of AGI-aspiring architectures. We conclude the paper with an evaluation of the degree to which several common AI approaches and architectures meet these requirements.