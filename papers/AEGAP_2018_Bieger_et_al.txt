Requirements for General Intelligence: A Case Study in Trustworthy Cumulative Learning for Air Traffic Control
Jordi Bieger and Kristinn R. Thórisson

While many evaluation procedures have been proposed in past research for artificial general intelligence (AGI), few take the time to carefully list the (minimum, general) requirements that an AGI-aspiring (cognitive) control architecture is intended to eventually meet. Such requirements could guide the design process and help evaluate the potential of an architecture to become generally intelligent—not through measuring the performance of a running AI system, but through a white-box, offline evaluation of what requirements have been met to what degree. We analyze the requirements on a more concrete task from the air traffic control (ATC) domain, and while this has some interesting aspects relevant for AI research in and of itself, it has many things in common with the requirements for AGI and has clear relevance to the field as a whole. To avoid major disruptions to proven workflows in safety-critical domains, a trustworthy, robust and adaptable AI system must work side-by-side with a human operator and cumulatively learn new tasks that can gradually be introduced into the operator’s complex workflow. Our analysis results in a set of minimal/necessary requirements that can guide the development of AGI-aspiring architectures. We then evaluate the degree to which several common AI approaches and architectures meet these requirements.